{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics.solutions import distance_calculation\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "names = model.model.names\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture(\"people_walking.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Set new dimensions\n",
    "new_w, new_h = 640, 360  # Example: Resize to 640x360\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\n",
    "    \"distance_calculation.avi\",\n",
    "    cv2.VideoWriter_fourcc(*\"mp4v\"), \n",
    "    fps,\n",
    "    (new_w, new_h)  # Use the new dimensions\n",
    ")\n",
    "\n",
    "# Init distance-calculation obj\n",
    "dis_obj = distance_calculation.DistanceCalculation()\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "    \n",
    "    # Resize the frame\n",
    "    im0_resized = cv2.resize(im0, (new_w, new_h))\n",
    "    \n",
    "    # Uncomment the following line if distance calculation is needed\n",
    "    im0_resized = dis_obj.calculate(im0_resized)\n",
    "    \n",
    "    # Write resized frame to the output video\n",
    "    video_writer.write(im0_resized)\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "from ultralytics.solutions.solutions import BaseSolution\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "\n",
    "class DistanceCalculation(BaseSolution):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initializes the DistanceCalculation class for measuring object distances in video streams.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Mouse event information\n",
    "        self.selected_points = []  # List to store selected points\n",
    "        self.annotator = None  # Annotator will be initialized in calculate method\n",
    "\n",
    "    def mouse_event_for_distance(self, event, x, y, flags, param):\n",
    "        \"\"\"\n",
    "        Handles mouse events to select points for distance calculation.\n",
    "        \"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            if len(self.selected_points) < 4:  # Allow a maximum of 4 points to be selected\n",
    "                self.selected_points.append((x, y))\n",
    "                print(f\"Point selected: {x}, {y}\")\n",
    "\n",
    "        elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "            self.selected_points = []  # Reset selection on right click\n",
    "            print(\"Selection reset.\")\n",
    "\n",
    "    def calculate(self, im0):\n",
    "        \"\"\"\n",
    "        Processes a video frame and calculates the distance between selected points.\n",
    "        \"\"\"\n",
    "        # Initialize annotator (although we won't use it for circles/lines)\n",
    "        self.annotator = Annotator(im0)  # Initialize annotator, but we will use OpenCV directly\n",
    "\n",
    "        # If at least two points are selected, calculate distance between them\n",
    "        if len(self.selected_points) >= 2:\n",
    "            for i, (x1, y1) in enumerate(self.selected_points):\n",
    "                for j, (x2, y2) in enumerate(self.selected_points):\n",
    "                    if i < j:  # Avoid recalculating the same pair (i, j)\n",
    "                        # Calculate Euclidean distance between the two points\n",
    "                        pixels_distance = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "                        # Round the distance for display\n",
    "                        distance_str = str(round(pixels_distance, 2))\n",
    "\n",
    "                        # Annotate the points and the distance on the image using OpenCV\n",
    "                        # Draw circles on the selected points\n",
    "                        cv2.circle(im0, (x1, y1), 5, (0, 0, 255), -1)  # Red circle for point 1\n",
    "                        cv2.circle(im0, (x2, y2), 5, (0, 0, 255), -1)  # Red circle for point 2\n",
    "\n",
    "                        # Plot the line between points\n",
    "                        cv2.line(im0, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green line\n",
    "\n",
    "                        # Midpoint to annotate the distance\n",
    "                        mid_point = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                        cv2.putText(im0, distance_str, mid_point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        # Display the image with annotations\n",
    "        self.display_output(im0)\n",
    "        cv2.setMouseCallback(\"Ultralytics Solutions\", self.mouse_event_for_distance)\n",
    "\n",
    "        return im0  # Return output image for further usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics.solutions import distance_calculation\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#image read\n",
    "\n",
    "# image = cv2.imread(\"processed_image.jpg\")\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture(r\"c:\\Users\\abdul\\Downloads\\How to use Dental X-Ray Film .mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Set new dimensions\n",
    "new_w, new_h = 640, 360  # Example: Resize to 640x360\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\n",
    "    \"distance_calculation.avi\",\n",
    "    cv2.VideoWriter_fourcc(*\"mp4v\"), \n",
    "    fps,\n",
    "    (new_w, new_h)  # Use the new dimensions\n",
    ")\n",
    "\n",
    "# Init distance-calculation obj\n",
    "dis_obj = DistanceCalculation()\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "    \n",
    "    # Resize the frame\n",
    "    im0_resized = cv2.resize(im0, (new_w, new_h))\n",
    "    \n",
    "    # Uncomment the following line if distance calculation is needed\n",
    "    im0_resized = dis_obj.calculate(im0_resized)\n",
    "    \n",
    "    # Write resized frame to the output video\n",
    "    video_writer.write(im0_resized)\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics Solutions:  {'region': None, 'show_in': True, 'show_out': True, 'colormap': None, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'json_file': None}\n",
      "Point selected: 202, 160\n",
      "Point selected: 164, 303\n",
      "Point selected: 161, 311\n",
      "Point selected: 151, 329\n",
      "Key pressed: 27\n",
      "ESC key pressed. Exiting.\n",
      "Processed image saved to output_image.png\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import cv2\n",
    "from ultralytics.solutions.solutions import BaseSolution\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "\n",
    "class DistanceCalculation(BaseSolution):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initializes the DistanceCalculation class for measuring object distances in images.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.selected_points = []  # List to store selected points\n",
    "\n",
    "    def mouse_event_for_distance(self, event, x, y, flags, param):\n",
    "        \"\"\"\n",
    "        Handles mouse events to select points for distance calculation.\n",
    "        \"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            if len(self.selected_points) < 4:  # Allow a maximum of 4 points to be selected\n",
    "                self.selected_points.append((x, y))\n",
    "                print(f\"Point selected: {x}, {y}\")\n",
    "        elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "            self.selected_points = []  # Reset selection on right click\n",
    "            print(\"Selection reset.\")\n",
    "\n",
    "    def calculate(self, im0):\n",
    "        \"\"\"\n",
    "        Processes an image and calculates the distance between selected points.\n",
    "        \"\"\"\n",
    "        # Create a copy of the original image for drawing\n",
    "        output_image = im0.copy()\n",
    "\n",
    "        # If at least two points are selected, calculate distance between them\n",
    "        if len(self.selected_points) >= 2:\n",
    "            for i, (x1, y1) in enumerate(self.selected_points):\n",
    "                for j, (x2, y2) in enumerate(self.selected_points):\n",
    "                    if i < j:  # Avoid recalculating the same pair (i, j)\n",
    "                        # Calculate Euclidean distance between the two points\n",
    "                        pixels_distance = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "                        # Round the distance for display\n",
    "                        distance_str = str(round(pixels_distance, 2))\n",
    "\n",
    "                        # Annotate the points and the distance on the image\n",
    "                        cv2.circle(output_image, (x1, y1), 3, (0, 0, 255), -1)  # Red circle\n",
    "                        cv2.circle(output_image, (x2, y2), 3, (0, 0, 255), -1)  # Red circle\n",
    "                        cv2.line(output_image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green line\n",
    "                        mid_point = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                        cv2.putText(output_image, distance_str, mid_point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        return output_image\n",
    "\n",
    "\n",
    "def process_image(file_path, output_path):\n",
    "    \"\"\"\n",
    "    Loads an image, allows distance calculations using mouse events, and saves the result.\n",
    "    \"\"\"\n",
    "    im0 = cv2.imread(file_path)\n",
    "    if im0 is None:\n",
    "        print(\"Error: Image not found or could not be read.\")\n",
    "        return\n",
    "\n",
    "    dis_obj = DistanceCalculation()\n",
    "\n",
    "    # Create a window\n",
    "    window_name = \"Distance Calculation\"\n",
    "    cv2.namedWindow(window_name)\n",
    "    cv2.setMouseCallback(window_name, dis_obj.mouse_event_for_distance)\n",
    "\n",
    "    while True:\n",
    "        # Show the image with annotations\n",
    "        im0_resized = dis_obj.calculate(im0)\n",
    "        cv2.imshow(window_name, im0_resized)\n",
    "\n",
    "        # Wait for a key press\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key != 255:  # Debugging: Print any key press for troubleshooting\n",
    "            print(f\"Key pressed: {key}\")\n",
    "\n",
    "        if key == 27:  # Exit on ESC key (ASCII code 27)\n",
    "            print(\"ESC key pressed. Exiting.\")\n",
    "            break\n",
    "\n",
    "    # Save the annotated image\n",
    "    cv2.imwrite(output_path, dis_obj.calculate(im0))\n",
    "    print(f\"Processed image saved to {output_path}\")\n",
    "\n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "process_image(r\"runs\\pose\\predict18\\image0.jpg\", \"output_image.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in .\\myenv\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in .\\myenv\\lib\\site-packages (from opencv-python-headless) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 1 Xray_tooth, 79.4ms\n",
      "Speed: 3.6ms preprocess, 79.4ms inference, 141.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: ultralytics.engine.results.Keypoints object\n",
      "masks: None\n",
      "names: {0: 'Xray_tooth'}\n",
      "obb: None\n",
      "orig_img: array([[[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  4,   0,   0],\n",
      "        [  2,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [109, 104, 105],\n",
      "        [ 74,  73,  69],\n",
      "        [101, 104,  95]],\n",
      "\n",
      "       [[  5,   1,   0],\n",
      "        [  3,   1,   0],\n",
      "        [  2,   2,   2],\n",
      "        ...,\n",
      "        [ 98,  93,  94],\n",
      "        [ 57,  57,  51],\n",
      "        [ 95,  98,  89]],\n",
      "\n",
      "       [[ 64,  59,  60],\n",
      "        [ 62,  60,  60],\n",
      "        [ 61,  61,  61],\n",
      "        ...,\n",
      "        [121, 123, 123],\n",
      "        [106, 110, 104],\n",
      "        [161, 166, 157]]], dtype=uint8)\n",
      "orig_shape: (375, 250)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\pose\\\\predict19'\n",
      "speed: {'preprocess': 3.643035888671875, 'inference': 79.3912410736084, 'postprocess': 141.3266658782959}]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'boxes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 102\u001b[0m\n\u001b[0;32m     98\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Example usage with YOLOv8 model\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m \u001b[43mprocess_image_with_yolo_v8\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mpose\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mpredict18\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mimage0.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_image_yolov8.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 75\u001b[0m, in \u001b[0;36mprocess_image_with_yolo_v8\u001b[1;34m(file_path, output_path)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Process the detected bounding boxes (centers of the boxes)\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxes\u001b[49m\u001b[38;5;241m.\u001b[39mxyxy:  \u001b[38;5;66;03m# Get the coordinates of the bounding boxes\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     x1, y1, x2, y2 \u001b[38;5;241m=\u001b[39m box[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     77\u001b[0m     center_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((x1 \u001b[38;5;241m+\u001b[39m x2) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'boxes'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO  # Import the YOLOv8 model\n",
    "\n",
    "class DistanceCalculation:\n",
    "    \"\"\"\n",
    "    A class for measuring object distances in images by auto-detecting points.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the DistanceCalculation class.\"\"\"\n",
    "        self.selected_points = []  # List to store detected points\n",
    "\n",
    "    def detect_points(self, im0, max_points=4):\n",
    "        \"\"\"\n",
    "        Automatically detects key points in the image using Shi-Tomasi Corner Detection.\n",
    "        \"\"\"\n",
    "        # Convert image to grayscale for corner detection\n",
    "        gray = cv2.cvtColor(im0, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect corners using Shi-Tomasi method\n",
    "        corners = cv2.goodFeaturesToTrack(gray, max_points, 0.01, 10)\n",
    "        corners = np.int0(corners)  # Convert to integer coordinates\n",
    "\n",
    "        # Clear existing points and add new detected points\n",
    "        self.selected_points = [(int(x), int(y)) for [x, y] in corners]\n",
    "        print(f\"Auto-detected points: {self.selected_points}\")\n",
    "\n",
    "    def calculate(self, im0):\n",
    "        \"\"\"\n",
    "        Draws the detected points and calculates distances between them.\n",
    "        \"\"\"\n",
    "        # Create a copy of the image to draw annotations\n",
    "        output_image = im0.copy()\n",
    "\n",
    "        # Annotate the detected points and calculate distances\n",
    "        if len(self.selected_points) >= 2:\n",
    "            for i, (x1, y1) in enumerate(self.selected_points):\n",
    "                for j, (x2, y2) in enumerate(self.selected_points):\n",
    "                    if i < j:  # Only calculate for unique pairs\n",
    "                        # Calculate Euclidean distance\n",
    "                        distance = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "                        # Draw points, line, and distance\n",
    "                        cv2.circle(output_image, (x1, y1), 5, (0, 0, 255), -1)  # Red point\n",
    "                        cv2.circle(output_image, (x2, y2), 5, (0, 0, 255), -1)  # Red point\n",
    "                        cv2.line(output_image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green line\n",
    "\n",
    "                        # Annotate the distance at the midpoint\n",
    "                        mid_x, mid_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "                        cv2.putText(output_image, f\"{distance:.2f}\", (mid_x, mid_y),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        return output_image\n",
    "\n",
    "\n",
    "def process_image_with_yolo_v8(file_path, output_path):\n",
    "    \"\"\"\n",
    "    Automatically detects objects using YOLOv8, calculates distances, and saves the result.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    im0 = cv2.imread(file_path)\n",
    "    if im0 is None:\n",
    "        print(f\"Error: Could not read the image at {file_path}\")\n",
    "        return\n",
    "\n",
    "    # Initialize the YOLOv8 model\n",
    "    model = YOLO(r'file\\runs\\train\\weights\\best.pt')  # Load a pre-trained YOLOv8 model (YOLOv8n is a smaller version)\n",
    "\n",
    "    # Use YOLOv8 to detect objects\n",
    "    results = model(im0)  # Run detection\n",
    "    detected_points = []\n",
    "    print(results)\n",
    "    # Process the detected bounding boxes (centers of the boxes)\n",
    "    for box in results.boxes.xyxy:  # Get the coordinates of the bounding boxes\n",
    "        x1, y1, x2, y2 = box[0]\n",
    "        center_x = int((x1 + x2) / 2)\n",
    "        center_y = int((y1 + y2) / 2)\n",
    "        detected_points.append((center_x, center_y))\n",
    "\n",
    "    # Initialize the distance calculation object\n",
    "    dis_obj = DistanceCalculation()\n",
    "\n",
    "    # Update the selected points with detected YOLO points\n",
    "    dis_obj.selected_points = detected_points\n",
    "    print(f\"YOLOv8 detected points: {dis_obj.selected_points}\")\n",
    "\n",
    "    # Calculate and save the annotated image\n",
    "    output_image = dis_obj.calculate(im0)\n",
    "    cv2.imwrite(output_path, output_image)\n",
    "    print(f\"Processed image saved at {output_path}\")\n",
    "\n",
    "    # Display the annotated image\n",
    "    window_name = \"YOLOv8 Object Detection with Distance Calculation\"\n",
    "    cv2.imshow(window_name, output_image)\n",
    "    print(\"Press any key to close the window.\")\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Example usage with YOLOv8 model\n",
    "process_image_with_yolo_v8(\"runs\\pose\\predict18\\image0.jpg\", \"output_image_yolov8.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "cap = cv2.VideoCapture(\"people_walking.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"distance_calculation.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init distance-calculation obj\n",
    "distance = solutions.DistanceCalculation(model=\"yolo11n.pt\", show=True)\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "    im0 = distance.calculate(im0)\n",
    "    video_writer.write(im0)\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"yck6wEmRC5evuqo3P3kA\")\n",
    "project = rf.workspace(\"abdul-aziz-dgqpw\").project(\"tooth-x-ray-zf9da\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import Image,display\n",
    "import cv2\n",
    "\n",
    "# import wandb # use for kaggle GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = r'file\\runs\\train\\weights\\best.pt'\n",
    "#best_model = f'{HOME}/train (5)/kaggle/working/runs/detect/train/weights/best.pt'\n",
    "# last_model = f'{HOME}train (5)\\kaggle\\working\\runs\\detect\\train\\weights\\last.pt'\n",
    "model = YOLO(best_model)\n",
    "# model = YOLO(\"yolov8n-pose.pt\")\n",
    "model.predict(\n",
    "    source=r\"1112.png\",\n",
    "    conf=0.25,\n",
    "    show=True,\n",
    "    save=True,  # Saves the visualization with skeletons\n",
    "    device=0,\n",
    "    show_conf = True, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 2 Xray_tooths, 49.4ms\n",
      "Speed: 0.0ms preprocess, 49.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Results saved to \u001b[1mruns\\pose\\predict18\u001b[0m\n",
      "129\n",
      "53\n",
      "Error: Not all key points were detected in the image.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def calculate_bone_loss(blue, yellow, mint, red):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of radiographic bone loss.\n",
    "\n",
    "    Parameters:\n",
    "    blue (tuple): Coordinates of the CEJ (Cementoenamel Junction) (x, y).\n",
    "    yellow (tuple): Coordinates of the existing bone level (x, y).\n",
    "    mint (tuple): Coordinates of the bone crest level (x, y).\n",
    "    red (tuple): Coordinates of the root apex (x, y).\n",
    "\n",
    "    Returns:\n",
    "    float: Percentage of bone loss.\n",
    "    \"\"\"\n",
    "    # Calculate Euclidean distances\n",
    "    distance_A = math.sqrt((mint[0] - yellow[0])**2 + (mint[1] - yellow[1])**2)\n",
    "    distance_B = math.sqrt((mint[0] - red[0])**2 + (mint[1] - red[1])**2)\n",
    "    \n",
    "    if distance_B == 0:\n",
    "        raise ValueError(\"Distance_B cannot be zero (division by zero).\")\n",
    "    \n",
    "    # Calculate percentage\n",
    "    percentage_bone_loss = (distance_A / distance_B) * 100\n",
    "    return percentage_bone_loss\n",
    "\n",
    "def process_image(image_path, yolo_model):\n",
    "    \"\"\"\n",
    "    Detect key points in the image and calculate bone loss.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (str): Path to the input image.\n",
    "    yolo_model: Pre-trained YOLO model.\n",
    "\n",
    "    Returns:\n",
    "    float: Percentage of bone loss.\n",
    "    \"\"\"\n",
    "    # Read the input image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image not found at {image_path}\")\n",
    "\n",
    "    # Perform YOLO inference to detect points\n",
    "    results = yolo_model.predict(source=image, save=True, save_txt=False)  # YOLO inference\n",
    "\n",
    "    print (results)\n",
    "\n",
    "\n",
    "    # Initialize key point coordinates\n",
    "    blue, yellow, mint, red = None, None, None, None\n",
    "\n",
    "    # Extract detections from YOLO results\n",
    "    detections = results[0].boxes\n",
    "    for box in detections:\n",
    "        # Calculate center of bounding box\n",
    "        x_center = int((box.xyxy[0][0] + box.xyxy[0][2]) / 2)\n",
    "        y_center = int((box.xyxy[0][1] + box.xyxy[0][3]) / 2)\n",
    "        print(x_center)\n",
    "\n",
    "        # Get the class label (0=Blue, 1=Yellow, 2=Mint, 3=Red)\n",
    "        label = int(box.cls[0])\n",
    "\n",
    "        # Assign coordinates based on label\n",
    "        if label == 0:  # Blue (CEJ)\n",
    "            blue = (x_center, y_center)\n",
    "        elif label == 1:  # Yellow (Existing bone level)\n",
    "            yellow = (x_center, y_center)\n",
    "        elif label == 2:  # Mint (Bone crest level)\n",
    "            mint = (x_center, y_center)\n",
    "        elif label == 3:  # Red (Root apex)\n",
    "            red = (x_center, y_center)\n",
    "\n",
    "    # Ensure all key points are detected\n",
    "    if blue is None or yellow is None or mint is None or red is None:\n",
    "        raise ValueError(\"Not all key points were detected in the image.\")\n",
    "\n",
    "    # Calculate bone loss percentage\n",
    "    percentage_bone_loss = calculate_bone_loss(blue, yellow, mint, red)\n",
    "\n",
    "    # Visualize the detections on the image\n",
    "    cv2.circle(image, blue, 5, (255, 0, 0), -1)    # Blue dot (CEJ)\n",
    "    cv2.circle(image, yellow, 5, (0, 255, 255), -1)  # Yellow dot (Existing bone level)\n",
    "    cv2.circle(image, mint, 5, (0, 255, 0), -1)     # Mint dot (Bone crest level)\n",
    "    cv2.circle(image, red, 5, (0, 0, 255), -1)      # Red dot (Root apex)\n",
    "\n",
    "    # Save and display the output image\n",
    "    output_path = \"output_image_with_points.jpg\"\n",
    "    cv2.imwrite(output_path, image)\n",
    "    display(Image(filename=output_path))\n",
    "\n",
    "    return percentage_bone_loss\n",
    "\n",
    "# Example usage\n",
    "image_path = \"1112.png\"  # Replace with your input image path\n",
    "yolo_model = YOLO(r'file\\runs\\train\\weights\\best.pt')  # Load the trained YOLO model\n",
    "\n",
    "# Process the image and calculate bone loss\n",
    "try:\n",
    "    bone_loss_percentage = process_image(image_path, yolo_model)\n",
    "    print(f\"The percentage of bone loss is: {bone_loss_percentage:.2f}%\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
